# ThoughtCompletion

AI-помощник для организации мыслей в VS Code. Помогает структурировать документы: переговорные планы, брейнштормы, оценки проектов и многое другое.

## Возможности

- **Продолжение структуры** — предлагает следующие заголовки, пункты и разделы на основе контекста документа
- **Заполнение содержимого** — развивает конкретные пункты, когда курсор находится внутри текста
- **Определение типа документа** — автоматически определяет тип документа или позволяет настроить свои типы
- **Поддержка локальных LLM** — работает с Ollama и любым OpenAI-совместимым API (LM Studio, LocalAI, LiteLLM и др.)
- **Полуавтоматический режим** — настраиваемая задержка или только ручной режим для экономии
- **Настраиваемый лимит токенов** — для моделей с «размышлением» (Qwen3 и др.)

## Требования

- VS Code 1.85.0 или выше
- Запущенный Ollama (`ollama serve`) или доступ к OpenAI-совместимому API

## Установка

### Из VSIX
```bash
cd ThoughtCompletion
npm install
npm run compile
vsce package
# Установите сгенерированный .vsix через меню Расширения в VS Code
```

### Разработка
Нажмите `F5` в VS Code для запуска Extension Development Host.

## Настройки расширения

| Настройка | По умолчанию | Описание |
|-----------|--------------|----------|
| `thoughtCompletion.provider` | `ollama` | LLM-провайдер (`openai` или `ollama`) |
| `thoughtCompletion.triggerMode` | `auto` | `auto` — после задержки, `manual` — только по команде |
| `thoughtCompletion.completionDelay` | `2500` | Задержка в мс перед автоматическим срабатыванием (500-10000) |
| `thoughtCompletion.maxTokens` | `1000` | Макс. токенов для ответа LLM (100-4000, увеличьте для thinking-моделей) |
| `thoughtCompletion.autoComplete` | `true` | Включить inline-дополнения (когда triggerMode = auto) |
| `thoughtCompletion.activeDocumentType` | `auto` | Тип документа (`auto` для автоопределения или конкретный тип) |
| `thoughtCompletion.documentTypes` | `[]` | Пользовательские типы документов |

### Настройки OpenAI
| Настройка | По умолчанию | Описание |
|-----------|--------------|----------|
| `thoughtCompletion.openai.baseUrl` | `https://api.openai.com/v1` | OpenAI-совместимый endpoint |
| `thoughtCompletion.openai.apiKey` | `` | API ключ |
| `thoughtCompletion.openai.model` | `gpt-4o-mini` | Название модели |

### Настройки Ollama
| Настройка | По умолчанию | Описание |
|-----------|--------------|----------|
| `thoughtCompletion.ollama.baseUrl` | `http://localhost:11434/v1` | Ollama API endpoint |
| `thoughtCompletion.ollama.model` | `llama3.2` | Название модели |

## Горячие клавиши

| Сочетание | Команда |
|-----------|---------|
| `Cmd+Shift+Enter` | Вызвать дополнение (автоопределение режима) |
| `Cmd+Shift+]` | Принудительное продолжение структуры |
| `Cmd+Shift+[` | Принудительное заполнение содержимого |

> Примечание: сочетания работают только в Markdown и plaintext файлах.

## Команды

- `ThoughtCompletion: Trigger Completion` — сгенерировать дополнение (автоопределение)
- `ThoughtCompletion: Continue Structure` — продолжить структуру
- `ThoughtCompletion: Fill Blank` — заполнить содержимое
- `ThoughtCompletion: Detect Document Type` — определить тип документа
- `ThoughtCompletion: Select Document Type` — выбрать тип документа вручную

## Встроенные типы документов

- **negotiation** — переговорные планы со сторонами, интересами, BATNA
- **brainstorm** — креативная генерация идей
- **project-evaluation** — оценка проекта с критериями и метриками
- **meeting-notes** — документирование встреч с action items
- **research-notes** — организация исследований с источниками
- **decision-document** — анализ решений с вариантами и критериями

## Пользовательские типы документов

Добавьте свои типы в настройках:

```json
{
  "thoughtCompletion.documentTypes": [
    {
      "name": "sales-proposal",
      "detectionPrompt": "Документ содержит ценообразование, ценностное предложение или выгоды для клиента",
      "workingPrompt": "Структурируй предложение с чёткими ценностными пунктами, отработай возражения, включи обоснование цены."
    }
  ]
}
```

## Решение проблем

### Thinking-модели (Qwen3 и др.)
При использовании моделей с «размышлением» увеличьте `maxTokens` до 2000-4000, чтобы модель успела завершить reasoning и выдать результат.

### Проблемы с прокси
Расширение использует прямые подключения (обходит прокси VS Code). Это хорошо работает для локальных сервисов, но может потребовать настройки для внешних API.

## Лицензия

MIT
